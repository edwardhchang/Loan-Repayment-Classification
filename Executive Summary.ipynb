{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcfbefda-1262-4a24-8fd7-9793cedadbb8",
   "metadata": {},
   "source": [
    "### Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f012e-379d-42f7-bb6d-abb8cc093e62",
   "metadata": {},
   "source": [
    "Peer-to-peer(P2P) lending is a growing space that is overtaking an area generally inhabited by traditional financial institutions. P2P lending resembles crowd-funding but for the loan space, where investors select which loans they will partially fund based upon borrower characteristics and loan details.  Loans provide the opportunity to link up lenders with those in need of capital. The investors make profit due to interest tacked onto the loan. Borrowers benefit as they can find competitive or even cheaper interest rates for loans in an efficient and cost-effective way (online). PricewaterhouseCoopers LLP projects P2P lending originations to grow to 150 billion USD by 2025. With a cost, the P2P lending industry is inherently risk due to the lack of collateral in loan agreements as well as information assymetry between the investor and borrower. Sadly, not all loans see their principal paid until the end, and when the loan is not paid-in-full (PIF) then the loan is charged-off. When this occurs, the lender loses money and due to the chance of charge-off when it comes to microloans, it is imperative that the platforms providing this link between lenders and borrowers have a risk model to mitigate potential charge-off based on borrower information. This study aims to train several machine learning models to classify if a borrower will repay the loan or potentially charge-off using Lending Tree data from 2007 - 2018. Lending Tree has been providing open-source data from their loan applications, but have since halted in 2020. The guiding metric will be the area under the ROC curve (AUC), specifically the precision-recall AUC score due to the severity of false negatives, or loans that our model incorrectly predicts as valid, but actually will most likely charge-off. We will also keep an eye on the recall score of our predictions as a higher recall score indiciates less false negatives. \n",
    "\n",
    "Our data was imported as a .csv file from Kaggle with 2.26 million samples with 151 features. We removed features that would not be included on a traditional loan screening as well as features alluding to joint applications as we only dove into individual applications. We also filtered our all samples that did not have a loan status of 'Fully Paid' or 'Charged-Off'. We simplified various categorical variables, specifically, 'term', 'emp_length',and 'home_ownership'. FICO score came in ranges and so we had to feature engineer the average of the FICO score as well as drop outliers created due to the averaging. We also engineered a feature using the datetime values 'issue_d', which indicates the issue date of the loan, as well as the 'earliest_cr_line', which indicates the year and month the earliest credit file was created. We imputed null values for columns, using median, mode, and mean depending on the data type. We lastly transformed the annual income feature to its log form due to a heavy right skew found in exploratory data analysis. \n",
    "\n",
    "We chose to model using logistic regressions, random forest classifiers, K-nearest neighbors classifiers, and deep neural networks. We selected these models as they represented different types of machine learning algorithms: linear, non-linear, ensemble, and articial neural network. For each model, we ran a default model and then tuned for hyperparameters using cross-validated grid-search. We ran the Random Forest model first with the intention of using it for feature selection. For the random forest classifier, we tuned the number of trees ('n_estimators'), the max number of features, the max depth of each tree, and whether to bootstrap. For the logistic regression, we tuned the the C-parameter which is the inverse of lambda, or the regularization strength. We also tuned for 'class_weight' to see how the model would deal with imbalanced classes on its own, as well as tuning for max iterations as the model failed to converage occasionally. For the K-Nearest Neighbors classifier, we tuned the number of neighbors, the distance metric used for the tree, as well as the weights used for function. Our deep neural networks required manual tweaking of network structure and regularization due to training times using grid search. We finally used a grid search using dropout for regularization as well as tuning for number of neurons in each layer and number of hidden layers. We created predictions and probabilities for each model and exported each for evaluation. \n",
    "Overall, logistic regressions had the fastest training times, whereas K-Nearest Neighbors took the longest. We increased the batch size when fitting our neural networks to speed up each epoch, but the networks would, without a doubt, show higher scores if run on a larger number of epochs. Our baseline model was created using a DummyClassifer from the scikit-learn machine learning library. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
